title: $:/plugins/tiddlywiki/ai-tools/servers/openai
tags: $:/tags/AI/CompletionServer
url: https://api.openai.com/v1/chat/completions
caption: OpenAI Service

<!--
Wikified JSON text to be sent to server
-->
\procedure json-prompt()
\rules only filteredtranscludeinline transcludeinline macrodef macrocallinline html conditional commentblock commentinline
{
	"model": "gpt-4o",
	"messages": [
		{
			"role": "system",
			"content": "<$text text={{{ [<conversationTitle>get[system-prompt]jsonstringify[]] }}}/>"
		}
		<!-- Loop through the tiddlers tagged with this one to pick up all the messages in the conversation -->
		<$list filter="[all[shadows+tiddlers]tag<conversationTitle>!is[draft]sort[created]]">
			,
			{
				<!-- We use JSON stringify to escape the characters that can't be used directly in JSON -->
				"role": "<$text text={{{ [<currentTiddler>get[role]jsonstringify[]] }}}/>",
				"content": [
					{
						"type": "text",
						"text": "<<ai-tools-get-message>>"
					}
					<%if [<currentTiddler>get[image]else[]!match[]] %>
						,
						{
							"type": "image_url",
							"image_url": {
								"url": "<$text text={{{ [[data:]] [<currentTiddler>get[image]get[type]] [[;base64,]] [<currentTiddler>get[image]get[text]jsonstringify[]] +[join[]] }}}/>"
							}
						}
					<%endif%>
				]
				
			}
		</$list>
	]
}
\end json-prompt

<!--
Callback for the HTTP response from the LLM
-->
\procedure completion-callback()
	<%if [<status>compare:number:gteq[200]compare:number:lteq[299]] %>
		<!-- Success -->
		<$action-createtiddler
			$basetitle=<<resultTitlePrefix>>
			tags=<<resultTags>>
			type="text/markdown"
			role={{{ [<data>jsonget[choices],[0],[message],[role]] }}}
			text={{{ [<data>jsonget[choices],[0],[message],[content]] }}}
		/>
	<%else%>
		<!-- Error -->
		<$action-createtiddler
			$basetitle=<<resultTitlePrefix>>
			tags=<<resultTags>>
			type="text/markdown"
			role="error"
			text={{{ [[Error:]] [<statusText>] [<data>jsonget[error],[message]]  +[join[]] }}}
		/>
	<%endif%>
\end completion-callback
